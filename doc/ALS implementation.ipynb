{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nicole's updates\n",
    "+ cleaned the data\n",
    "+ preprocessed by creating ratings matrix\n",
    "+ Implemented ALS with user and item bias(fast matrix solutions)\n",
    "+ temporality added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 20 16  6  4  1 10 11 12  8 21  3 14 22 18 17 23 19 15  2  9  7 13]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#read in the data\n",
    "data = pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "\n",
    "#get the necessary dimensions\n",
    "n_users = data['userId'].nunique()\n",
    "n_movies = data['movieId'].nunique()\n",
    "#split the data into different bins for the temporal function\n",
    "def get_bin(num):\n",
    "    #subtracts 25 because they started collecting the data 25 years after january 1970\n",
    "    return int((num)/(60*60*24*365)) - 25\n",
    "data[\"bin\"] = data[\"timestamp\"].apply(get_bin)\n",
    "data_groups = data.groupby(\"bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create R matrix\n",
    "n_users = data.userId.unique().shape[0]\n",
    "n_items = data.movieId.unique().shape[0]\n",
    "movieIds = sorted(data.movieId.unique())\n",
    "\n",
    "R_init = np.zeros((n_users, n_items))\n",
    "bin_match = np.zeros((n_users, n_items)) \n",
    "\n",
    "#stored the bin number for each user movie pair\n",
    "for row in data.itertuples():\n",
    "    #print(row)\n",
    "    R_init[row[1]-1, movieIds.index(row[2])] = row[3]\n",
    "    bin_match[row[1]-1, movieIds.index(row[2])] = int(row[5]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(R, R_hat):\n",
    "    #only for the that had ratings in the training matrix\n",
    "    mask = (R>0)\n",
    "    R_hat[mask] = 0 #set the values we don't need predictions for to 0 \n",
    "    return np.sqrt(((R - R_hat)**2).mean()) #return the RMSE\n",
    "\n",
    "def predict(U, M, mu,b_i, b_u, bin_match ,B_i_bint):\n",
    "    R = np.zeros((n_users, n_movies))\n",
    "    #do we need to iterate over time as well\n",
    "    for u in range(n_users):#iterate over users\n",
    "        for i in range(n_movies):#iterate over movies\n",
    "            bin_num = int(bin_match[u,i]) #get the bin number for user u and movie i\n",
    "            R[u,i] = mu+b_u[u]+b_i[i]+B_i_bint[bin_num,i]+np.dot(U[u,:],M[i,:].T)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate implementation from online resource\n",
    "np.random.seed(1)\n",
    "def train(Mat, bin_match, f, lambda_, n_iter):\n",
    "    R = Mat[:]\n",
    "    # Step 1 Initialize matrix M by assigning the average rating for that movie as the first row, and small random numbers for the remaining entries.\n",
    "    M = np.random.rand(n_movies,f)\n",
    "    M[:,0] = R.sum(0)/(R!=0).sum(0).astype(float)\n",
    "    \n",
    "    U = np.random.rand(n_users,f)#initialize U matrix\n",
    "    \n",
    "    mu = R.sum()/(R!=0).sum().astype(float)#average rating\n",
    "    b_i = np.random.rand(n_movies)#initialize b_i = len(movies)\n",
    "    b_u = np.random.rand(n_users) #initialize b_u = len(users)\n",
    "    B_i_bint = np.random.rand(data['bin'].nunique(),n_movies)\n",
    "    \n",
    "    #function to minimize: sum(r_ui - ^r_ui) + lambda(b_i^2 + b_u^2+ |q|^2 + |p|^2 )\n",
    "    for epoch in range(n_iter):\n",
    "        #Step 2 Fix M, Solve U by minimizing the objective function\n",
    "        for i in range(n_users):\n",
    "            I_i = np.nonzero(R[i,:])[0] #set of movies that user i rated\n",
    "            n_ui = len(I_i) #number of ratings user i has given \n",
    "            E = np.identity(f+1)\n",
    "            idx = np.vstack([bin_match[i,I_i], I_i]).astype(int)\n",
    "            r_u = R[i,I_i] - b_i[I_i] - mu #- B_i_bint[tuple(idx)]\n",
    "            m = np.ones((n_movies,1))\n",
    "            M_p = np.concatenate((m,M),1)\n",
    "            M_Ii = M_p[I_i,:]\n",
    "            u_prime = np.linalg.solve((np.dot(M_Ii.T,M_Ii)+(lambda_*E)), np.dot(r_u,M_Ii))\n",
    "            b_u[i] = u_prime[0]\n",
    "            U[i,:] = u_prime[1:]\n",
    "           \n",
    "        #Step 3 Fix U, solve M by minimizing the objective function similarly; \n",
    "        for j in range(n_movies):\n",
    "            I_j = np.nonzero(R[:,j])[0] #set of users that rated movie j\n",
    "            n_mj = len(I_j) #number of users that rated movie j\n",
    "            matches = bin_match[I_j,j].astype(int) #the t for each user with movie j\n",
    "            r_j = R[I_j,j] - b_u[I_j] - mu #- B_i_bint[matches,j]\n",
    "            \n",
    "            u = np.ones((n_users,1))\n",
    "            U_p = np.concatenate((u,U),1)\n",
    "            U_Ij = U_p[I_j,:]\n",
    "            m_prime = np.linalg.solve((np.dot(U_Ij.T,U_Ij)+(lambda_*E)), np.dot(r_j,U_Ij))\n",
    "            b_i[j] = m_prime[0]\n",
    "            M[j,:] = m_prime[1:]\n",
    "            \n",
    "            #if the movie is not represented in the training data\n",
    "            if(np.linalg.norm(m_prime)==0):\n",
    "                b_i[j] = np.random.rand(1)\n",
    "                M[j,:] = np.random.rand(f)\n",
    "            \n",
    "        for t in range(len(B_i_bint)):\n",
    "            mask = bin_match == t\n",
    "            for i in range(n_movies):\n",
    "                r_it = R[:,i][mask[:,i]]- mu - b_u[mask[:,i]] - b_i[i]- np.dot(U[mask[:,i]], M[i,:])\n",
    "                B_i_bint[t,i] = np.sum(r_it)/(len(r_it)+lambda_)                                                   \n",
    "    \n",
    "        R_hat = predict(U, M, mu,b_i, b_u, bin_match ,B_i_bint)\n",
    "        error = get_error(R, R_hat)\n",
    "        print(\"iteration: \", epoch, \"; error: \", error)\n",
    "    \n",
    "    return U, M,mu, b_u, b_i, B_i_bint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat(df):\n",
    "    R = np.zeros((n_users, n_items))\n",
    "    bin_match = np.zeros((n_users, n_items)) \n",
    "    for row in df.itertuples():\n",
    "        R[row[1]-1, movieIds.index(row[2])] = row[3]\n",
    "        bin_match[row[1]-1, movieIds.index(row[2])] = int(row[5]-1)\n",
    "    return R, bin_match\n",
    "\n",
    "def get_fold(data,K):\n",
    "    fold_num = []\n",
    "    i =0\n",
    "    while i<len(data):\n",
    "        for j in range(5):\n",
    "            if(i<len(data)):\n",
    "                fold_num.append(j)\n",
    "            i+=1\n",
    "    return fold_num\n",
    "\n",
    "def cv(X, K, f, lambda_):\n",
    "    df = X\n",
    "    df['fold'] = get_fold(X,K)\n",
    "    test_errors = []\n",
    "    train_errors = []\n",
    "    for k in range(K):\n",
    "        k_test = df[df.fold == k]\n",
    "        k_train = df[df.fold != k]\n",
    "        k_train_mat, k_train_bins = get_mat(k_train)\n",
    "        k_test_mat, k_test_bins = get_mat(k_test)\n",
    "        \n",
    "        #get the parameters\n",
    "        k_train_U, k_train_M, k_train_mu, k_train_b_u, k_train_b_i, k_train_B_i_bint = train(k_train_mat, k_train_bins, f, lambda_, 10)\n",
    "        k_train_hat = predict(k_train_U, k_train_M, k_train_mu,k_train_b_i, k_train_b_u, k_train_bins ,k_train_B_i_bint)\n",
    "        \n",
    "        #get training error\n",
    "        train_error = get_error(k_train_mat, k_train_hat)\n",
    "        train_errors.append(train_error)\n",
    "        \n",
    "        #get the prediction\n",
    "        k_test_hat = predict(k_train_U, k_train_M, k_train_mu,k_train_b_i, k_train_b_u, k_test_bins ,k_train_B_i_bint)\n",
    "        error = get_error(k_test_mat, k_test_hat)\n",
    "        test_errors.append(error)\n",
    "        \n",
    "    return train_errors, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cross validation and test\n",
    "f_s = [2,4,10]\n",
    "lambda_s= [0.1,1,5] \n",
    "\n",
    "#train for 10 iterarions each time\n",
    "trains = []\n",
    "tests = []\n",
    "for f in f_s:\n",
    "    train_avs = []\n",
    "    test_avs = []\n",
    "    for lambda_ in lambda_s:\n",
    "        tr_errors, tst_errors = cv(data, 5, f, lambda_ )\n",
    "        train_avs.append(np.mean(tr_errors))\n",
    "        test_avs.append(np.mean(tsts_errors))\n",
    "    trains.append(train_avs)\n",
    "    tests.append(test_avs)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0 ; error:  1.0130919367469948\n",
      "iteration:  1 ; error:  1.0211000354852295\n",
      "iteration:  2 ; error:  1.0092809914287368\n",
      "iteration:  3 ; error:  0.9908420348674676\n",
      "iteration:  4 ; error:  0.9750583486014992\n",
      "iteration:  5 ; error:  0.957940669181787\n",
      "iteration:  6 ; error:  0.942690096086655\n",
      "iteration:  7 ; error:  0.9299880764557014\n",
      "iteration:  8 ; error:  0.9179181591838389\n",
      "iteration:  9 ; error:  0.9064293709629213\n",
      "iteration:  10 ; error:  0.8960901432643429\n",
      "iteration:  11 ; error:  0.887588243068184\n",
      "iteration:  12 ; error:  0.8785941233749645\n",
      "iteration:  13 ; error:  0.8718596255276074\n",
      "iteration:  14 ; error:  0.865749162727699\n",
      "iteration:  15 ; error:  0.8604561397686332\n",
      "iteration:  16 ; error:  0.8572941642992202\n",
      "iteration:  17 ; error:  0.8515870520533017\n",
      "iteration:  18 ; error:  0.848712384656291\n",
      "iteration:  19 ; error:  0.8459221610975864\n"
     ]
    }
   ],
   "source": [
    "#using the final train data 80%\n",
    "df = pd.read_csv(\"../output/data_train.csv\")[[\"userId\",\"movieId\",\"rating\",\"timestamp\",\"bin_num\"]]\n",
    "\n",
    "R, bins = get_mat(df)\n",
    "U, M, mu, b_u, b_i, B_i_bint = train(R, bins,10, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8941\n"
     ]
    }
   ],
   "source": [
    "print(df.movieId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(U.T).to_csv(\"../output/P_ALS.csv\")\n",
    "#pd.DataFrame(M.T).to_csv(\"../output/Q_ALS.csv\")\n",
    "#pd.DataFrame(b_u).to_csv(\"../output/b_user_ALS.csv\")\n",
    "pd.DataFrame(np.array([b_i]).T).to_csv(\"../output/b_item_ALS.csv\")\n",
    "pd.DataFrame(B_i_bint).to_csv(\"../output/b_time_ALS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
